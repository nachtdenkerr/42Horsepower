Writing training job pid to /opt/ml/training_worker.pid: 47
Training Worker Args: Namespace(aws_region='us-east-1', checkpoint_dir='./checkpoint_sagemaker', environment_s3_key=None, framework='tensorflow', model_metadata_s3_key='s3://aws-deepracer-data-us-east-1-1/data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/model_metadata.json', preset_s3_key=None, pretrained_checkpoint_dir='./pretrained_checkpoint_sagemaker', pretrained_s3_bucket=None, pretrained_s3_prefix='sagemaker', s3_bucket='aws-deepracer-data-us-east-1-1', s3_prefix='data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/')
[s3] Successfully downloaded model metadata                  from s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/model_metadata.json to local ./custom_files/agent/model_metadata.json.
Sensor list ['FRONT_FACING_CAMERA'], network DEEP_CONVOLUTIONAL_NETWORK_SHALLOW, simapp_version 5.0, training_algorithm clipped_ppo, action_space_type discrete lidar_config {'num_sectors': 8, 'num_values_per_sector': 8, 'clipping_dist': 2.0}
Action space from file: [{'steering_angle': -20.0, 'speed': 0.5, 'index': 0}, {'steering_angle': -12.5, 'speed': 1.0, 'index': 1}, {'steering_angle': -10.0, 'speed': 1.3, 'index': 2}, {'steering_angle': -7.5, 'speed': 1.8, 'index': 3}, {'steering_angle': -7.5, 'speed': 1.0, 'index': 4}, {'steering_angle': -5.0, 'speed': 2.0, 'index': 5}, {'steering_angle': -5.0, 'speed': 1.2, 'index': 6}, {'steering_angle': -2.5, 'speed': 2.2, 'index': 7}, {'steering_angle': -2.5, 'speed': 1.2, 'index': 8}, {'steering_angle': 0.0, 'speed': 2.5, 'index': 9}, {'steering_angle': 0.0, 'speed': 2.3, 'index': 10}, {'steering_angle': 0.0, 'speed': 2.0, 'index': 11}, {'steering_angle': 0.0, 'speed': 1.7, 'index': 12}, {'steering_angle': 2.5, 'speed': 1.2, 'index': 13}, {'steering_angle': 2.5, 'speed': 2.2, 'index': 14}, {'steering_angle': 5.0, 'speed': 2.1, 'index': 15}, {'steering_angle': 5.0, 'speed': 1.2, 'index': 16}, {'steering_angle': 7.5, 'speed': 1.9, 'index': 17}, {'steering_angle': 7.5, 'speed': 1.0, 'index': 18}, {'steering_angle': 10.0, 'speed': 1.7, 'index': 19}, {'steering_angle': 10.0, 'speed': 1.0, 'index': 20}, {'steering_angle': 12.5, 'speed': 1.5, 'index': 21}, {'steering_angle': 12.5, 'speed': 0.9, 'index': 22}, {'steering_angle': 15.0, 'speed': 1.2, 'index': 23}, {'steering_angle': 15.0, 'speed': 0.8, 'index': 24}, {'steering_angle': 17.5, 'speed': 1.1, 'index': 25}, {'steering_angle': 20.0, 'speed': 1.0, 'index': 26}, {'steering_angle': 20.0, 'speed': 0.6, 'index': 27}]
Using the following hyper-parameters
{
  "batch_size": 64,
  "beta_entropy": 0.01,
  "discount_factor": 0.95,
  "e_greedy_value": 1.0,
  "epsilon_steps": 10000,
  "exploration_type": "categorical",
  "loss_type": "huber",
  "lr": 0.0005,
  "num_episodes_between_training": 20,
  "num_epochs": 10,
  "stack_size": 1,
  "term_cond_avg_score": 100000.0,
  "term_cond_max_episodes": 100000
}
[s3] Successfully uploaded hyperparameters to                  s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/ip/hyperparameters.json.
Hostname: ip-10-0-73-226.ec2.internal
[s3] Successfully uploaded ip address to                  s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/ip/ip.json.
[s3] Successfully uploaded ip done to                  s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/ip/done.
## Creating graph - name: MultiAgentGraphManager
## Start physics before creating graph
## Create graph
## Creating agent - name: agent
[RL] Created agent loggers
[RL] Dynamic import of memory:  "DeepRacerMemoryParameters" {
    "load_memory_from_file_path": null,
    "max_size": [
        "<MemoryGranularity.Transitions: 0>",
        1000000
    ],
    "n_step": -1,
    "shared_memory": false,
    "train_to_eval_ratio": 1
}
[RL] Dynamically imported of memory <markov.memories.deepracer_memory.DeepRacerMemory object at 0x7f298e462dc0>
[RL] Setting devices
[RL] Setting filters
[RL] Setting filter devices: numpy
[RL] Setting Phase
[RL] After setting Phase
[RL] Setting signals
[RL] Agent init successful
[RL] ActorCriticAgent init
[RL] ActorCriticAgent  init successful
## Created agent: agent
/root/anaconda/envs/sagemaker_env/lib/python3.8/site-packages/rl_coach/architectures/tensorflow_components/layers.py:119: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.
  return tf.compat.v1.layers.conv2d(input_layer, filters=self.num_filters, kernel_size=self.kernel_size,
/root/anaconda/envs/sagemaker_env/lib/python3.8/site-packages/rl_coach/architectures/tensorflow_components/layers.py:181: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  return tf.compat.v1.layers.dense(input_layer, self.units, name=name, kernel_initializer=kernel_initializer,
/root/anaconda/envs/sagemaker_env/lib/python3.8/site-packages/rl_coach/architectures/tensorflow_components/layers.py:181: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.
  return tf.compat.v1.layers.dense(input_layer, self.units, name=name, kernel_initializer=kernel_initializer,
/root/anaconda/envs/sagemaker_env/lib/python3.8/site-packages/rl_coach/architectures/tensorflow_components/layers.py:119: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.
  return tf.compat.v1.layers.conv2d(input_layer, filters=self.num_filters, kernel_size=self.kernel_size,
## Stop physics after creating graph
## Creating session
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/0_Step-0.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 0
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
Unable to find deepracer checkpoint json
Unable to find the best deepracer checkpoint number. Getting the last checkpoint number
Unable to find deepracer checkpoint json
Unable to find the last deepracer checkpoint number.
Unable to find deepracer checkpoint json
Unable to find the last deepracer checkpoint number.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_0.pb
Best checkpoint number: -1, Last checkpoint number: -1
Copying the frozen checkpoint from ./frozen_models/agent/model_0.pb to /opt/ml/model/agent/model.pb.
Unable to find deepracer checkpoint json
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
[s3] Successfully uploaded .ready to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.ready.
DoorMan: installing SIGINT, SIGTERM
Training> Name=main_level/agent, Worker=0, Episode=1, Total reward=0, Steps=30, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=2, Total reward=0, Steps=88, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=3, Total reward=0, Steps=130, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=4, Total reward=0, Steps=181, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=5, Total reward=0, Steps=226, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=6, Total reward=0, Steps=246, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=7, Total reward=0, Steps=265, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=8, Total reward=0, Steps=295, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=9, Total reward=0, Steps=311, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=10, Total reward=0, Steps=339, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=11, Total reward=0, Steps=368, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=12, Total reward=0, Steps=387, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=13, Total reward=0, Steps=413, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=14, Total reward=0, Steps=436, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=15, Total reward=0, Steps=455, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=16, Total reward=0, Steps=475, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=17, Total reward=0, Steps=496, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=18, Total reward=0, Steps=535, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=19, Total reward=0, Steps=565, Training iteration=0
Training> Name=main_level/agent, Worker=0, Episode=20, Total reward=0, Steps=602, Training iteration=0
Policy training> Surrogate loss=0.009632796980440617, KL divergence=0.013018030673265457, Entropy=3.3196463584899902, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.0222396831959486, KL divergence=0.012811819091439247, Entropy=3.3199503421783447, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.015409444458782673, KL divergence=0.016895102337002754, Entropy=3.3163418769836426, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.03513308987021446, KL divergence=0.01719249039888382, Entropy=3.3156356811523438, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.04172159731388092, KL divergence=0.017142564058303833, Entropy=3.3156754970550537, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.034585416316986084, KL divergence=0.016985168680548668, Entropy=3.3161532878875732, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.05011593550443649, KL divergence=0.013439686968922615, Entropy=3.319416046142578, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.06401893496513367, KL divergence=0.02127634361386299, Entropy=3.311469554901123, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.09809775650501251, KL divergence=0.028189539909362793, Entropy=3.3048276901245117, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.0929030328989029, KL divergence=0.04098033905029297, Entropy=3.2903456687927246, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/1_Step-602.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 1
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_1.pb
Best checkpoint number: 0, Last checkpoint number: 0
Copying the frozen checkpoint from ./frozen_models/agent/model_0.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Training> Name=main_level/agent, Worker=0, Episode=21, Total reward=0, Steps=639, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=22, Total reward=0, Steps=679, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=23, Total reward=0, Steps=699, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=24, Total reward=0, Steps=723, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=25, Total reward=0, Steps=758, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=26, Total reward=0, Steps=778, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=27, Total reward=0, Steps=795, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=28, Total reward=0, Steps=824, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=29, Total reward=0, Steps=843, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=30, Total reward=0, Steps=871, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=31, Total reward=0, Steps=900, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=32, Total reward=0, Steps=916, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=33, Total reward=0, Steps=939, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=34, Total reward=0, Steps=957, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=35, Total reward=0, Steps=974, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=36, Total reward=0, Steps=993, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=37, Total reward=0, Steps=1015, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=38, Total reward=0, Steps=1057, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=39, Total reward=0, Steps=1080, Training iteration=1
Training> Name=main_level/agent, Worker=0, Episode=40, Total reward=0, Steps=1107, Training iteration=1
Policy training> Surrogate loss=0.008820190094411373, KL divergence=0.009619263000786304, Entropy=3.3051929473876953, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.03701353073120117, KL divergence=0.02095225267112255, Entropy=3.305819034576416, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.09393782913684845, KL divergence=0.028987079858779907, Entropy=3.283332347869873, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.09969715029001236, KL divergence=0.025302695110440254, Entropy=3.2960269451141357, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.11228504031896591, KL divergence=0.04281442239880562, Entropy=3.259643793106079, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.11385135352611542, KL divergence=0.05146046355366707, Entropy=3.245920419692993, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.10975760966539383, KL divergence=0.04130283370614052, Entropy=3.2716610431671143, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.12903209030628204, KL divergence=0.05947918817400932, Entropy=3.2441704273223877, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.13211268186569214, KL divergence=0.07900454103946686, Entropy=3.212120294570923, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.11168836802244186, KL divergence=0.07066183537244797, Entropy=3.227048873901367, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/2_Step-1107.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 2
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_2.pb
Best checkpoint number: 0, Last checkpoint number: 0
Copying the frozen checkpoint from ./frozen_models/agent/model_0.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Training> Name=main_level/agent, Worker=0, Episode=41, Total reward=0, Steps=1129, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=42, Total reward=0, Steps=1180, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=43, Total reward=0, Steps=1200, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=44, Total reward=0, Steps=1230, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=45, Total reward=0, Steps=1272, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=46, Total reward=0, Steps=1300, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=47, Total reward=0, Steps=1318, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=48, Total reward=0, Steps=1359, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=49, Total reward=0, Steps=1380, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=50, Total reward=0, Steps=1397, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=51, Total reward=0, Steps=1473, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=52, Total reward=0, Steps=1492, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=53, Total reward=0, Steps=1535, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=54, Total reward=0, Steps=1554, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=55, Total reward=0, Steps=1572, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=56, Total reward=0, Steps=1592, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=57, Total reward=0, Steps=1613, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=58, Total reward=0, Steps=1642, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=59, Total reward=0, Steps=1677, Training iteration=2
Training> Name=main_level/agent, Worker=0, Episode=60, Total reward=0, Steps=1742, Training iteration=2
Policy training> Surrogate loss=0.003675968386232853, KL divergence=0.01801299676299095, Entropy=3.2394163608551025, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.0333278588950634, KL divergence=0.05102018639445305, Entropy=3.2177278995513916, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.07094027101993561, KL divergence=0.04678894579410553, Entropy=3.203526735305786, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.09414544701576233, KL divergence=0.05824735388159752, Entropy=3.200261116027832, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.14873169362545013, KL divergence=0.07456844300031662, Entropy=3.1691136360168457, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.13668113946914673, KL divergence=0.08843537420034409, Entropy=3.1461362838745117, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.12785227596759796, KL divergence=0.0872621089220047, Entropy=3.1620359420776367, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.15929867327213287, KL divergence=0.10275410115718842, Entropy=3.1274325847625732, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.11946608126163483, KL divergence=0.09516950696706772, Entropy=3.1440999507904053, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.1363774836063385, KL divergence=0.092026486992836, Entropy=3.1595852375030518, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/3_Step-1742.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 3
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_3.pb
Best checkpoint number: 1, Last checkpoint number: 1
Copying the frozen checkpoint from ./frozen_models/agent/model_1.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Training> Name=main_level/agent, Worker=0, Episode=61, Total reward=0, Steps=1766, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=62, Total reward=0, Steps=1789, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=63, Total reward=0, Steps=1808, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=64, Total reward=0, Steps=1846, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=65, Total reward=0, Steps=1901, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=66, Total reward=0, Steps=1919, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=67, Total reward=0, Steps=1938, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=68, Total reward=0, Steps=1967, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=69, Total reward=0, Steps=2017, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=70, Total reward=0, Steps=2048, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=71, Total reward=0, Steps=2089, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=72, Total reward=0, Steps=2109, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=73, Total reward=0, Steps=2129, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=74, Total reward=0, Steps=2147, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=75, Total reward=0, Steps=2168, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=76, Total reward=0, Steps=2188, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=77, Total reward=0, Steps=2209, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=78, Total reward=0, Steps=2260, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=79, Total reward=0, Steps=2301, Training iteration=3
Training> Name=main_level/agent, Worker=0, Episode=80, Total reward=0, Steps=2363, Training iteration=3
Policy training> Surrogate loss=0.0017190244980156422, KL divergence=0.01801176927983761, Entropy=3.1545677185058594, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.07339548319578171, KL divergence=0.05427416041493416, Entropy=3.139235496520996, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.12092897295951843, KL divergence=0.06484445184469223, Entropy=3.1300294399261475, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.09046333283185959, KL divergence=0.08644869178533554, Entropy=3.0621230602264404, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.09040439128875732, KL divergence=0.09211936593055725, Entropy=3.0829873085021973, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.14095650613307953, KL divergence=0.08807764202356339, Entropy=3.058529853820801, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.12848514318466187, KL divergence=0.07361577451229095, Entropy=3.1058084964752197, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.11349275708198547, KL divergence=0.07576476037502289, Entropy=3.1068551540374756, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.11998169869184494, KL divergence=0.07784441858530045, Entropy=3.102257490158081, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.1096719354391098, KL divergence=0.07329341769218445, Entropy=3.121351718902588, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/4_Step-2363.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 4
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_4.pb
Best checkpoint number: 2, Last checkpoint number: 2
Copying the frozen checkpoint from ./frozen_models/agent/model_2.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'0'}
Training> Name=main_level/agent, Worker=0, Episode=81, Total reward=0, Steps=2402, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=82, Total reward=0, Steps=2428, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=83, Total reward=0, Steps=2447, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=84, Total reward=0, Steps=2483, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=85, Total reward=0, Steps=2521, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=86, Total reward=0, Steps=2540, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=87, Total reward=0, Steps=2557, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=88, Total reward=0, Steps=2587, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=89, Total reward=0, Steps=2604, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=90, Total reward=0, Steps=2635, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=91, Total reward=0, Steps=2685, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=92, Total reward=0, Steps=2729, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=93, Total reward=0, Steps=2751, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=94, Total reward=0, Steps=2770, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=95, Total reward=0, Steps=2786, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=96, Total reward=0, Steps=2806, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=97, Total reward=0, Steps=2824, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=98, Total reward=0, Steps=2865, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=99, Total reward=0, Steps=2891, Training iteration=4
Training> Name=main_level/agent, Worker=0, Episode=100, Total reward=0, Steps=2950, Training iteration=4
Policy training> Surrogate loss=0.031792785972356796, KL divergence=0.017561087384819984, Entropy=3.079535722732544, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.0541728138923645, KL divergence=0.04987717419862747, Entropy=3.1325604915618896, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.08280536532402039, KL divergence=0.06417462974786758, Entropy=3.0543315410614014, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.10148472338914871, KL divergence=0.05326129496097565, Entropy=3.1143274307250977, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.10486865043640137, KL divergence=0.07372091710567474, Entropy=3.0338830947875977, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.11249285191297531, KL divergence=0.06299687922000885, Entropy=3.1139984130859375, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.12200331687927246, KL divergence=0.07391705363988876, Entropy=3.0670487880706787, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.11678401380777359, KL divergence=0.07630430161952972, Entropy=3.072857618331909, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.1259797364473343, KL divergence=0.0717521607875824, Entropy=3.09261417388916, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.11217731982469559, KL divergence=0.06719723343849182, Entropy=3.1003670692443848, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/5_Step-2950.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 5
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_5.pb
Best checkpoint number: 3, Last checkpoint number: 3
Copying the frozen checkpoint from ./frozen_models/agent/model_3.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'1'}
Training> Name=main_level/agent, Worker=0, Episode=101, Total reward=0, Steps=2975, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=102, Total reward=0, Steps=3020, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=103, Total reward=0, Steps=3074, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=104, Total reward=0, Steps=3100, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=105, Total reward=0, Steps=3169, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=106, Total reward=0, Steps=3188, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=107, Total reward=0, Steps=3203, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=108, Total reward=0, Steps=3235, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=109, Total reward=0, Steps=3259, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=110, Total reward=0, Steps=3293, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=111, Total reward=0, Steps=3339, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=112, Total reward=0, Steps=3362, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=113, Total reward=0, Steps=3400, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=114, Total reward=0, Steps=3419, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=115, Total reward=0, Steps=3435, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=116, Total reward=0, Steps=3472, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=117, Total reward=0, Steps=3495, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=118, Total reward=0, Steps=3531, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=119, Total reward=0, Steps=3556, Training iteration=5
Training> Name=main_level/agent, Worker=0, Episode=120, Total reward=0, Steps=3576, Training iteration=5
Policy training> Surrogate loss=0.019722990691661835, KL divergence=0.012965700589120388, Entropy=3.0806984901428223, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.059383876621723175, KL divergence=0.04338221997022629, Entropy=3.189986228942871, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.09104619175195694, KL divergence=0.09410181641578674, Entropy=2.991600513458252, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.09419436007738113, KL divergence=0.05896826460957527, Entropy=3.145382881164551, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.11395324766635895, KL divergence=0.08928174525499344, Entropy=3.0114829540252686, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.12706482410430908, KL divergence=0.07722072303295135, Entropy=3.066707134246826, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.11878326535224915, KL divergence=0.06352422386407852, Entropy=3.1440796852111816, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.11635417491197586, KL divergence=0.07352682203054428, Entropy=3.085160255432129, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.12599287927150726, KL divergence=0.07421817630529404, Entropy=3.0851340293884277, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.10816027224063873, KL divergence=0.06954285502433777, Entropy=3.1177010536193848, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/6_Step-3576.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 6
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_6.pb
Best checkpoint number: 4, Last checkpoint number: 4
Copying the frozen checkpoint from ./frozen_models/agent/model_4.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'2'}
Training> Name=main_level/agent, Worker=0, Episode=121, Total reward=0, Steps=3624, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=122, Total reward=0, Steps=3704, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=123, Total reward=0, Steps=3722, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=124, Total reward=0, Steps=3748, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=125, Total reward=0, Steps=3782, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=126, Total reward=0, Steps=3800, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=127, Total reward=0, Steps=3821, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=128, Total reward=0, Steps=3851, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=129, Total reward=0, Steps=3870, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=130, Total reward=0, Steps=3934, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=131, Total reward=0, Steps=3978, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=132, Total reward=0, Steps=3999, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=133, Total reward=0, Steps=4018, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=134, Total reward=0, Steps=4036, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=135, Total reward=0, Steps=4058, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=136, Total reward=0, Steps=4087, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=137, Total reward=0, Steps=4107, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=138, Total reward=0, Steps=4135, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=139, Total reward=0, Steps=4165, Training iteration=6
Training> Name=main_level/agent, Worker=0, Episode=140, Total reward=0, Steps=4236, Training iteration=6
Policy training> Surrogate loss=0.004805582109838724, KL divergence=0.01743941567838192, Entropy=3.0476675033569336, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.06921958923339844, KL divergence=0.050093911588191986, Entropy=3.079768657684326, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.09196576476097107, KL divergence=0.07051173597574234, Entropy=3.020702838897705, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.10460368543863297, KL divergence=0.07205642014741898, Entropy=3.0071187019348145, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.11638126522302628, KL divergence=0.07082884013652802, Entropy=3.043523073196411, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.11513519287109375, KL divergence=0.07603700459003448, Entropy=3.00685453414917, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.12780342996120453, KL divergence=0.07093437016010284, Entropy=3.023061513900757, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.12389936298131943, KL divergence=0.06888014823198318, Entropy=3.031520366668701, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.12765593826770782, KL divergence=0.06461697816848755, Entropy=3.051302671432495, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.12687189877033234, KL divergence=0.07165171205997467, Entropy=3.0273804664611816, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/7_Step-4236.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 7
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_7.pb
Best checkpoint number: 5, Last checkpoint number: 5
Copying the frozen checkpoint from ./frozen_models/agent/model_5.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'3'}
Training> Name=main_level/agent, Worker=0, Episode=141, Total reward=0, Steps=4275, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=142, Total reward=0, Steps=4355, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=143, Total reward=0, Steps=4427, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=144, Total reward=0, Steps=4471, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=145, Total reward=0, Steps=4512, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=146, Total reward=0, Steps=4545, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=147, Total reward=0, Steps=4565, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=148, Total reward=0, Steps=4594, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=149, Total reward=0, Steps=4613, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=150, Total reward=0, Steps=4658, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=151, Total reward=0, Steps=4690, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=152, Total reward=0, Steps=4742, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=153, Total reward=0, Steps=4764, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=154, Total reward=0, Steps=4785, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=155, Total reward=0, Steps=4806, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=156, Total reward=0, Steps=4825, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=157, Total reward=0, Steps=4843, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=158, Total reward=0, Steps=4875, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=159, Total reward=0, Steps=4908, Training iteration=7
Training> Name=main_level/agent, Worker=0, Episode=160, Total reward=0, Steps=4940, Training iteration=7
Policy training> Surrogate loss=0.013961497694253922, KL divergence=0.015186075121164322, Entropy=3.0446617603302, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.08636576682329178, KL divergence=0.047042980790138245, Entropy=3.0419936180114746, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.11235876381397247, KL divergence=0.05503629148006439, Entropy=3.018734931945801, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.12341747432947159, KL divergence=0.058790743350982666, Entropy=3.050585985183716, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.12926362454891205, KL divergence=0.06772005558013916, Entropy=3.0089895725250244, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.13315439224243164, KL divergence=0.06378836184740067, Entropy=3.030926465988159, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.13576239347457886, KL divergence=0.0704972892999649, Entropy=2.990191698074341, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.13644607365131378, KL divergence=0.06253784894943237, Entropy=3.0445587635040283, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.1382063329219818, KL divergence=0.06650345772504807, Entropy=3.033459424972534, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.1391388326883316, KL divergence=0.06797622889280319, Entropy=3.0194437503814697, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/8_Step-4940.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 8
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_8.pb
Best checkpoint number: 5, Last checkpoint number: 6
Copying the frozen checkpoint from ./frozen_models/agent/model_5.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'4'}
Training> Name=main_level/agent, Worker=0, Episode=161, Total reward=0, Steps=4991, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=162, Total reward=0, Steps=5038, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=163, Total reward=0, Steps=5059, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=164, Total reward=0, Steps=5119, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=165, Total reward=0, Steps=5151, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=166, Total reward=0, Steps=5168, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=167, Total reward=0, Steps=5190, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=168, Total reward=0, Steps=5220, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=169, Total reward=0, Steps=5239, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=170, Total reward=0, Steps=5281, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=171, Total reward=0, Steps=5328, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=172, Total reward=0, Steps=5347, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=173, Total reward=0, Steps=5388, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=174, Total reward=0, Steps=5409, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=175, Total reward=0, Steps=5429, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=176, Total reward=0, Steps=5447, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=177, Total reward=0, Steps=5466, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=178, Total reward=0, Steps=5539, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=179, Total reward=0, Steps=5563, Training iteration=8
Training> Name=main_level/agent, Worker=0, Episode=180, Total reward=0, Steps=5595, Training iteration=8
Policy training> Surrogate loss=0.015368935652077198, KL divergence=0.00917268730700016, Entropy=3.072747230529785, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.09576717019081116, KL divergence=0.03755084425210953, Entropy=3.008985757827759, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.10957606881856918, KL divergence=0.054605595767498016, Entropy=2.9784936904907227, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.12882646918296814, KL divergence=0.05652293562889099, Entropy=3.0110514163970947, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.12743054330348969, KL divergence=0.061227161437273026, Entropy=3.001509189605713, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.13182216882705688, KL divergence=0.06943805515766144, Entropy=2.97509765625, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.13554401695728302, KL divergence=0.06758825480937958, Entropy=2.996948719024658, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.13941480219364166, KL divergence=0.06760607659816742, Entropy=2.978569507598877, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.1418434977531433, KL divergence=0.06151606887578964, Entropy=3.013136386871338, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.1401936113834381, KL divergence=0.06063542887568474, Entropy=3.0231471061706543, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/9_Step-5595.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 9
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_9.pb
Best checkpoint number: 5, Last checkpoint number: 7
Copying the frozen checkpoint from ./frozen_models/agent/model_5.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'6'}
Training> Name=main_level/agent, Worker=0, Episode=181, Total reward=0, Steps=5648, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=182, Total reward=0, Steps=5710, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=183, Total reward=0, Steps=5726, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=184, Total reward=0, Steps=5771, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=185, Total reward=0, Steps=5798, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=186, Total reward=0, Steps=5825, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=187, Total reward=0, Steps=5847, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=188, Total reward=0, Steps=5874, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=189, Total reward=0, Steps=5890, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=190, Total reward=0, Steps=5922, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=191, Total reward=0, Steps=5950, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=192, Total reward=0, Steps=5998, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=193, Total reward=0, Steps=6022, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=194, Total reward=0, Steps=6043, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=195, Total reward=0, Steps=6063, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=196, Total reward=0, Steps=6082, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=197, Total reward=0, Steps=6110, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=198, Total reward=0, Steps=6193, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=199, Total reward=0, Steps=6236, Training iteration=9
Training> Name=main_level/agent, Worker=0, Episode=200, Total reward=0, Steps=6317, Training iteration=9
Policy training> Surrogate loss=0.005195763893425465, KL divergence=0.007617305498570204, Entropy=3.080251455307007, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.07470934838056564, KL divergence=0.038628675043582916, Entropy=3.110569953918457, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.10696358978748322, KL divergence=0.063874751329422, Entropy=2.986415147781372, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.12455970793962479, KL divergence=0.05898832157254219, Entropy=3.0895164012908936, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.1342991143465042, KL divergence=0.0855078473687172, Entropy=2.9619269371032715, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.13010837137699127, KL divergence=0.06690755486488342, Entropy=3.0570871829986572, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.1445685476064682, KL divergence=0.06873776018619537, Entropy=3.0516433715820312, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.1353660374879837, KL divergence=0.07071860879659653, Entropy=3.0405287742614746, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.1382114738225937, KL divergence=0.06760654598474503, Entropy=3.0623857975006104, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.13857026398181915, KL divergence=0.06401749700307846, Entropy=3.080976724624634, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/10_Step-6317.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 10
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_10.pb
Best checkpoint number: 5, Last checkpoint number: 8
Copying the frozen checkpoint from ./frozen_models/agent/model_5.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'7'}
Training> Name=main_level/agent, Worker=0, Episode=201, Total reward=0, Steps=6348, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=202, Total reward=0, Steps=6411, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=203, Total reward=0, Steps=6438, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=204, Total reward=0, Steps=6493, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=205, Total reward=0, Steps=6529, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=206, Total reward=0, Steps=6547, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=207, Total reward=0, Steps=6568, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=208, Total reward=0, Steps=6600, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=209, Total reward=0, Steps=6621, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=210, Total reward=0, Steps=6655, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=211, Total reward=0, Steps=6690, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=212, Total reward=0, Steps=6713, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=213, Total reward=0, Steps=6736, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=214, Total reward=0, Steps=6754, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=215, Total reward=0, Steps=6777, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=216, Total reward=0, Steps=6793, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=217, Total reward=0, Steps=6817, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=218, Total reward=0, Steps=6845, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=219, Total reward=0, Steps=6876, Training iteration=10
Training> Name=main_level/agent, Worker=0, Episode=220, Total reward=0, Steps=6929, Training iteration=10
Policy training> Surrogate loss=0.031731341034173965, KL divergence=0.005860626231878996, Entropy=3.1082763671875, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.04890518635511398, KL divergence=0.0541968010365963, Entropy=2.9254674911499023, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.11632105708122253, KL divergence=0.0365118645131588, Entropy=3.063490867614746, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.12765900790691376, KL divergence=0.04264254868030548, Entropy=3.057506561279297, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.12247538566589355, KL divergence=0.049263764172792435, Entropy=3.035477876663208, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.1174030601978302, KL divergence=0.04790833592414856, Entropy=3.0485966205596924, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.09800460189580917, KL divergence=0.046838875859975815, Entropy=3.0543038845062256, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.12060727179050446, KL divergence=0.04728775843977928, Entropy=3.051815986633301, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.11746956408023834, KL divergence=0.04648945853114128, Entropy=3.0636093616485596, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.10869153589010239, KL divergence=0.048512473702430725, Entropy=3.0444746017456055, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/11_Step-6929.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 11
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_11.pb
Best checkpoint number: 5, Last checkpoint number: 9
Copying the frozen checkpoint from ./frozen_models/agent/model_5.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'8'}
Training> Name=main_level/agent, Worker=0, Episode=221, Total reward=0, Steps=6990, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=222, Total reward=0, Steps=7022, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=223, Total reward=0, Steps=7043, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=224, Total reward=0, Steps=7079, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=225, Total reward=0, Steps=7112, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=226, Total reward=0, Steps=7152, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=227, Total reward=0, Steps=7168, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=228, Total reward=0, Steps=7193, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=229, Total reward=0, Steps=7210, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=230, Total reward=0, Steps=7285, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=231, Total reward=0, Steps=7320, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=232, Total reward=0, Steps=7381, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=233, Total reward=0, Steps=7400, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=234, Total reward=0, Steps=7428, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=235, Total reward=0, Steps=7446, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=236, Total reward=0, Steps=7471, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=237, Total reward=0, Steps=7492, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=238, Total reward=0, Steps=7536, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=239, Total reward=0, Steps=7615, Training iteration=11
Training> Name=main_level/agent, Worker=0, Episode=240, Total reward=0, Steps=7655, Training iteration=11
Policy training> Surrogate loss=-0.0025991119910031557, KL divergence=0.02125474065542221, Entropy=3.019430637359619, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.07351357489824295, KL divergence=0.05225469917058945, Entropy=3.023672580718994, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.10821221023797989, KL divergence=0.0873643159866333, Entropy=2.9256982803344727, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.10911409556865692, KL divergence=0.07841439545154572, Entropy=3.0019118785858154, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.11863572150468826, KL divergence=0.07824695855379105, Entropy=2.998809576034546, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.11680595576763153, KL divergence=0.07158661633729935, Entropy=3.034585475921631, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.13763242959976196, KL divergence=0.06980877369642258, Entropy=3.040259599685669, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.1292114406824112, KL divergence=0.07513418048620224, Entropy=3.0076475143432617, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.12043081969022751, KL divergence=0.07321632653474808, Entropy=3.026628255844116, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.12015533447265625, KL divergence=0.07198439538478851, Entropy=3.043098211288452, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/12_Step-7655.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 12
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_12.pb
Best checkpoint number: 5, Last checkpoint number: 10
Copying the frozen checkpoint from ./frozen_models/agent/model_5.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'9'}
Training> Name=main_level/agent, Worker=0, Episode=241, Total reward=0, Steps=7717, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=242, Total reward=0, Steps=7777, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=243, Total reward=0, Steps=7796, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=244, Total reward=0, Steps=7827, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=245, Total reward=0, Steps=7851, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=246, Total reward=0, Steps=7883, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=247, Total reward=0, Steps=7904, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=248, Total reward=0, Steps=7947, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=249, Total reward=0, Steps=7964, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=250, Total reward=0, Steps=8034, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=251, Total reward=0, Steps=8068, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=252, Total reward=0, Steps=8104, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=253, Total reward=0, Steps=8125, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=254, Total reward=0, Steps=8145, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=255, Total reward=0, Steps=8191, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=256, Total reward=0, Steps=8212, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=257, Total reward=0, Steps=8236, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=258, Total reward=0, Steps=8371, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=259, Total reward=0, Steps=8512, Training iteration=12
Training> Name=main_level/agent, Worker=0, Episode=260, Total reward=0, Steps=8595, Training iteration=12
Policy training> Surrogate loss=0.008724424056708813, KL divergence=0.024105416610836983, Entropy=3.046107769012451, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.06819518655538559, KL divergence=0.07008775323629379, Entropy=3.0085384845733643, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.10584910213947296, KL divergence=0.06218700855970383, Entropy=3.0292675495147705, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.1320769339799881, KL divergence=0.07086097449064255, Entropy=2.994647741317749, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.13024549186229706, KL divergence=0.0705566331744194, Entropy=3.0054874420166016, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.14866682887077332, KL divergence=0.08375048637390137, Entropy=2.9739339351654053, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.13371050357818604, KL divergence=0.07377980649471283, Entropy=3.0236496925354004, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.1465090662240982, KL divergence=0.0802309513092041, Entropy=2.9808108806610107, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.15052472054958344, KL divergence=0.07310800999403, Entropy=3.031101703643799, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.1583382934331894, KL divergence=0.0797005221247673, Entropy=3.004122495651245, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/13_Step-8595.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 13
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_13.pb
Best checkpoint number: 5, Last checkpoint number: 11
Copying the frozen checkpoint from ./frozen_models/agent/model_5.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'10'}
Training> Name=main_level/agent, Worker=0, Episode=261, Total reward=0, Steps=8640, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=262, Total reward=0, Steps=8693, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=263, Total reward=0, Steps=8711, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=264, Total reward=0, Steps=8746, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=265, Total reward=0, Steps=8807, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=266, Total reward=0, Steps=8835, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=267, Total reward=0, Steps=8854, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=268, Total reward=0, Steps=8883, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=269, Total reward=0, Steps=8899, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=270, Total reward=0, Steps=8929, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=271, Total reward=0, Steps=8983, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=272, Total reward=0, Steps=9007, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=273, Total reward=0, Steps=9025, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=274, Total reward=0, Steps=9044, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=275, Total reward=0, Steps=9063, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=276, Total reward=0, Steps=9101, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=277, Total reward=0, Steps=9120, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=278, Total reward=0, Steps=9161, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=279, Total reward=0, Steps=9243, Training iteration=13
Training> Name=main_level/agent, Worker=0, Episode=280, Total reward=0, Steps=9266, Training iteration=13
Policy training> Surrogate loss=-0.002149745123460889, KL divergence=0.008067422546446323, Entropy=3.046232223510742, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.08191722631454468, KL divergence=0.0357087068259716, Entropy=3.010021686553955, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.10806344449520111, KL divergence=0.05117756128311157, Entropy=2.9880592823028564, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.11366057395935059, KL divergence=0.05113524943590164, Entropy=3.0218491554260254, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.12293770164251328, KL divergence=0.0626717209815979, Entropy=2.9422366619110107, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.13177910447120667, KL divergence=0.052875109016895294, Entropy=3.0139071941375732, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.12838496267795563, KL divergence=0.053388290107250214, Entropy=3.0099213123321533, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.11811760812997818, KL divergence=0.05664949491620064, Entropy=2.9891810417175293, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.1289893388748169, KL divergence=0.05693240091204643, Entropy=2.99884295463562, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.1219610720872879, KL divergence=0.05487179756164551, Entropy=3.0222015380859375, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/14_Step-9266.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 14
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_14.pb
Best checkpoint number: 12, Last checkpoint number: 12
Copying the frozen checkpoint from ./frozen_models/agent/model_12.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'11'}
Training> Name=main_level/agent, Worker=0, Episode=281, Total reward=0, Steps=9341, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=282, Total reward=0, Steps=9366, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=283, Total reward=0, Steps=9386, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=284, Total reward=0, Steps=9427, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=285, Total reward=0, Steps=9467, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=286, Total reward=0, Steps=9503, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=287, Total reward=0, Steps=9517, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=288, Total reward=0, Steps=9599, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=289, Total reward=0, Steps=9615, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=290, Total reward=0, Steps=9688, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=291, Total reward=0, Steps=9711, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=292, Total reward=0, Steps=9758, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=293, Total reward=0, Steps=9796, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=294, Total reward=0, Steps=9815, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=295, Total reward=0, Steps=9834, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=296, Total reward=0, Steps=9857, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=297, Total reward=0, Steps=9879, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=298, Total reward=0, Steps=9899, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=299, Total reward=0, Steps=9955, Training iteration=14
Training> Name=main_level/agent, Worker=0, Episode=300, Total reward=0, Steps=9992, Training iteration=14
Policy training> Surrogate loss=-0.001374373328872025, KL divergence=0.013053608126938343, Entropy=3.000945806503296, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.09004858136177063, KL divergence=0.04350903630256653, Entropy=3.0245003700256348, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.12217286229133606, KL divergence=0.058521952480077744, Entropy=2.9704885482788086, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.13481126725673676, KL divergence=0.06729856133460999, Entropy=2.9730660915374756, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.13770315051078796, KL divergence=0.07242606580257416, Entropy=2.9506967067718506, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.13646627962589264, KL divergence=0.06440431624650955, Entropy=2.9818170070648193, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.14331869781017303, KL divergence=0.0626019760966301, Entropy=2.999694585800171, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.14760422706604004, KL divergence=0.07065317779779434, Entropy=2.9644861221313477, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.13252820074558258, KL divergence=0.06651052832603455, Entropy=3.0124456882476807, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.13836397230625153, KL divergence=0.06603050976991653, Entropy=3.016913414001465, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/15_Step-9992.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 15
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_15.pb
Best checkpoint number: 12, Last checkpoint number: 13
Copying the frozen checkpoint from ./frozen_models/agent/model_12.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'13'}
Training> Name=main_level/agent, Worker=0, Episode=301, Total reward=0, Steps=10015, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=302, Total reward=0, Steps=10066, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=303, Total reward=0, Steps=10103, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=304, Total reward=0, Steps=10162, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=305, Total reward=0, Steps=10229, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=306, Total reward=0, Steps=10295, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=307, Total reward=0, Steps=10313, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=308, Total reward=0, Steps=10347, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=309, Total reward=0, Steps=10370, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=310, Total reward=0, Steps=10395, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=311, Total reward=0, Steps=10436, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=312, Total reward=0, Steps=10463, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=313, Total reward=0, Steps=10481, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=314, Total reward=0, Steps=10503, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=315, Total reward=0, Steps=10521, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=316, Total reward=0, Steps=10536, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=317, Total reward=0, Steps=10555, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=318, Total reward=0, Steps=10592, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=319, Total reward=0, Steps=10614, Training iteration=15
Training> Name=main_level/agent, Worker=0, Episode=320, Total reward=0, Steps=10639, Training iteration=15
Policy training> Surrogate loss=0.005905523896217346, KL divergence=0.02186061628162861, Entropy=2.9676055908203125, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.07773274183273315, KL divergence=0.04069285839796066, Entropy=3.056551933288574, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.10415635257959366, KL divergence=0.09963495284318924, Entropy=2.8648793697357178, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.11938108503818512, KL divergence=0.06684993952512741, Entropy=2.998593807220459, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.12664099037647247, KL divergence=0.06872006505727768, Entropy=2.995479106903076, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.12599018216133118, KL divergence=0.06322966516017914, Entropy=3.0069572925567627, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.13169844448566437, KL divergence=0.061735205352306366, Entropy=3.017843246459961, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.13264739513397217, KL divergence=0.05934571102261543, Entropy=3.022883892059326, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.12324570119380951, KL divergence=0.05755110830068588, Entropy=3.0324840545654297, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.12831905484199524, KL divergence=0.05595095083117485, Entropy=3.047370433807373, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/16_Step-10639.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 16
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_16.pb
Best checkpoint number: 12, Last checkpoint number: 14
Copying the frozen checkpoint from ./frozen_models/agent/model_12.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'5'}
Training> Name=main_level/agent, Worker=0, Episode=321, Total reward=0, Steps=10679, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=322, Total reward=0, Steps=10761, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=323, Total reward=0, Steps=10783, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=324, Total reward=0, Steps=10846, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=325, Total reward=0, Steps=10891, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=326, Total reward=0, Steps=10914, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=327, Total reward=0, Steps=10934, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=328, Total reward=0, Steps=10966, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=329, Total reward=0, Steps=10983, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=330, Total reward=0, Steps=11005, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=331, Total reward=0, Steps=11041, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=332, Total reward=0, Steps=11063, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=333, Total reward=0, Steps=11085, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=334, Total reward=0, Steps=11103, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=335, Total reward=0, Steps=11118, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=336, Total reward=0, Steps=11136, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=337, Total reward=0, Steps=11157, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=338, Total reward=0, Steps=11201, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=339, Total reward=0, Steps=11256, Training iteration=16
Training> Name=main_level/agent, Worker=0, Episode=340, Total reward=0, Steps=11348, Training iteration=16
Policy training> Surrogate loss=0.00868550781160593, KL divergence=0.012711811810731888, Entropy=2.9829964637756348, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.10817086696624756, KL divergence=0.03548179939389229, Entropy=2.979205846786499, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.12525230646133423, KL divergence=0.04804119095206261, Entropy=2.985450029373169, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.14242157340049744, KL divergence=0.06320607662200928, Entropy=2.9296000003814697, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.14246007800102234, KL divergence=0.05537969246506691, Entropy=2.9897820949554443, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.138342022895813, KL divergence=0.062243472784757614, Entropy=2.9530129432678223, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.14041972160339355, KL divergence=0.05634106695652008, Entropy=3.011549234390259, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.1428297758102417, KL divergence=0.06431899219751358, Entropy=2.9721741676330566, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.14131194353103638, KL divergence=0.05977778509259224, Entropy=3.0045881271362305, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.14500698447227478, KL divergence=0.058360788971185684, Entropy=3.0069258213043213, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/17_Step-11348.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 17
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_17.pb
Best checkpoint number: 12, Last checkpoint number: 15
Copying the frozen checkpoint from ./frozen_models/agent/model_12.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'14'}
Training> Name=main_level/agent, Worker=0, Episode=341, Total reward=0, Steps=11379, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=342, Total reward=0, Steps=11416, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=343, Total reward=0, Steps=11448, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=344, Total reward=0, Steps=11491, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=345, Total reward=0, Steps=11533, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=346, Total reward=0, Steps=11564, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=347, Total reward=0, Steps=11579, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=348, Total reward=0, Steps=11612, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=349, Total reward=0, Steps=11637, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=350, Total reward=0, Steps=11677, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=351, Total reward=0, Steps=11743, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=352, Total reward=0, Steps=11780, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=353, Total reward=0, Steps=11803, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=354, Total reward=0, Steps=11822, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=355, Total reward=0, Steps=11843, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=356, Total reward=0, Steps=11894, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=357, Total reward=0, Steps=11918, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=358, Total reward=0, Steps=12002, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=359, Total reward=0, Steps=12026, Training iteration=17
Training> Name=main_level/agent, Worker=0, Episode=360, Total reward=0, Steps=12089, Training iteration=17
Policy training> Surrogate loss=0.0029664330650120974, KL divergence=0.0165169108659029, Entropy=3.0096921920776367, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.07556162774562836, KL divergence=0.06200713291764259, Entropy=3.046055793762207, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.09962909668684006, KL divergence=0.06842805445194244, Entropy=3.002842903137207, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.10396310687065125, KL divergence=0.06257763504981995, Entropy=3.0561468601226807, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.11568605899810791, KL divergence=0.06233927235007286, Entropy=3.0483031272888184, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.12736894190311432, KL divergence=0.06394373625516891, Entropy=3.0282225608825684, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.12378363311290741, KL divergence=0.0699014961719513, Entropy=2.996180534362793, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.1129833236336708, KL divergence=0.07567445933818817, Entropy=2.9742231369018555, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.13190282881259918, KL divergence=0.06462119519710541, Entropy=3.0533273220062256, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.13510912656784058, KL divergence=0.0641138032078743, Entropy=3.0361688137054443, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/18_Step-12089.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 18
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_18.pb
Best checkpoint number: 16, Last checkpoint number: 16
Copying the frozen checkpoint from ./frozen_models/agent/model_16.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'15'}
Training> Name=main_level/agent, Worker=0, Episode=361, Total reward=0, Steps=12186, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=362, Total reward=0, Steps=12266, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=363, Total reward=0, Steps=12286, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=364, Total reward=0, Steps=12365, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=365, Total reward=0, Steps=12395, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=366, Total reward=0, Steps=12415, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=367, Total reward=0, Steps=12438, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=368, Total reward=0, Steps=12503, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=369, Total reward=0, Steps=12524, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=370, Total reward=0, Steps=12566, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=371, Total reward=0, Steps=12617, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=372, Total reward=0, Steps=12637, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=373, Total reward=0, Steps=12659, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=374, Total reward=0, Steps=12681, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=375, Total reward=0, Steps=12699, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=376, Total reward=0, Steps=12716, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=377, Total reward=0, Steps=12737, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=378, Total reward=0, Steps=12779, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=379, Total reward=0, Steps=12812, Training iteration=18
Training> Name=main_level/agent, Worker=0, Episode=380, Total reward=0, Steps=12828, Training iteration=18
Policy training> Surrogate loss=0.008707437664270401, KL divergence=0.012680300511419773, Entropy=2.9986798763275146, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.08971249312162399, KL divergence=0.05634891986846924, Entropy=2.913027763366699, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.1148407980799675, KL divergence=0.07140139490365982, Entropy=2.90854811668396, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.13747483491897583, KL divergence=0.08884827047586441, Entropy=2.874093770980835, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.1388832926750183, KL divergence=0.0735417902469635, Entropy=2.942889451980591, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.14445093274116516, KL divergence=0.07998839020729065, Entropy=2.9051706790924072, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.14723064005374908, KL divergence=0.08033475279808044, Entropy=2.9166390895843506, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.14680102467536926, KL divergence=0.07268945872783661, Entropy=2.9474220275878906, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.135562926530838, KL divergence=0.07531369477510452, Entropy=2.953848361968994, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.14474131166934967, KL divergence=0.0701722502708435, Entropy=2.9616570472717285, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/19_Step-12828.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 19
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_19.pb
Best checkpoint number: 16, Last checkpoint number: 17
Copying the frozen checkpoint from ./frozen_models/agent/model_16.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'12'}
Training> Name=main_level/agent, Worker=0, Episode=381, Total reward=0, Steps=12868, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=382, Total reward=0, Steps=12906, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=383, Total reward=0, Steps=12928, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=384, Total reward=0, Steps=12988, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=385, Total reward=0, Steps=13019, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=386, Total reward=0, Steps=13039, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=387, Total reward=0, Steps=13057, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=388, Total reward=0, Steps=13088, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=389, Total reward=0, Steps=13107, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=390, Total reward=0, Steps=13171, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=391, Total reward=0, Steps=13200, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=392, Total reward=0, Steps=13221, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=393, Total reward=0, Steps=13241, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=394, Total reward=0, Steps=13261, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=395, Total reward=0, Steps=13280, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=396, Total reward=0, Steps=13295, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=397, Total reward=0, Steps=13320, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=398, Total reward=0, Steps=13356, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=399, Total reward=0, Steps=13398, Training iteration=19
Training> Name=main_level/agent, Worker=0, Episode=400, Total reward=0, Steps=13418, Training iteration=19
Policy training> Surrogate loss=-0.008051072247326374, KL divergence=0.016939697787165642, Entropy=2.911600351333618, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.08966296911239624, KL divergence=0.05982087552547455, Entropy=2.8674378395080566, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.10820991545915604, KL divergence=0.055676281452178955, Entropy=2.9563543796539307, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.11670380085706711, KL divergence=0.07865405827760696, Entropy=2.866591453552246, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.11405538022518158, KL divergence=0.06575442850589752, Entropy=2.9384701251983643, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.12242458760738373, KL divergence=0.06545327603816986, Entropy=2.947443962097168, training epoch=5, learning_rate=0.0005
Policy training> Surrogate loss=-0.11496780812740326, KL divergence=0.06164789944887161, Entropy=2.984978437423706, training epoch=6, learning_rate=0.0005
Policy training> Surrogate loss=-0.12438693642616272, KL divergence=0.06173039972782135, Entropy=2.9835855960845947, training epoch=7, learning_rate=0.0005
Policy training> Surrogate loss=-0.1331610083580017, KL divergence=0.06585599482059479, Entropy=2.9526045322418213, training epoch=8, learning_rate=0.0005
Policy training> Surrogate loss=-0.11867409199476242, KL divergence=0.061655137687921524, Entropy=2.9762284755706787, training epoch=9, learning_rate=0.0005
Checkpoint> Saving in path=['./checkpoint_sagemaker/agent/20_Step-13418.ckpt']
[s3] Successfully uploaded .lock to                      s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.lock.
Uploaded 3 files for checkpoint 20
[s3] Successfully uploaded coach checkpoint to                   s3 bucket aws-deepracer-data-us-east-1-1 with s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/.coach_checkpoint.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
saved intermediate frozen graph: data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/model_20.pb
Best checkpoint number: 16, Last checkpoint number: 18
Copying the frozen checkpoint from ./frozen_models/agent/model_16.pb to /opt/ml/model/agent/model.pb.
[s3] Successfully downloaded deepracer checkpoint json from                  s3 key data-05655be1-0286-4912-ade0-5092015e8b62/models/44f25e39-a272-4aad-9dd6-89215bc16ba7/sagemaker-robomaker-artifacts/model/deepracer_checkpoints.json to local checkpoint_sagemaker/agent/deepracer_checkpoints.json.
Deleting the frozen models in s3 for the iterations: {'17'}
Training> Name=main_level/agent, Worker=0, Episode=401, Total reward=0, Steps=13488, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=402, Total reward=0, Steps=13515, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=403, Total reward=0, Steps=13534, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=404, Total reward=0, Steps=13563, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=405, Total reward=0, Steps=13629, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=406, Total reward=0, Steps=13678, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=407, Total reward=0, Steps=13695, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=408, Total reward=0, Steps=13720, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=409, Total reward=0, Steps=13743, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=410, Total reward=0, Steps=13817, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=411, Total reward=0, Steps=13865, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=412, Total reward=0, Steps=13885, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=413, Total reward=0, Steps=13908, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=414, Total reward=0, Steps=13932, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=415, Total reward=0, Steps=13953, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=416, Total reward=0, Steps=13997, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=417, Total reward=0, Steps=14023, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=418, Total reward=0, Steps=14044, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=419, Total reward=0, Steps=14074, Training iteration=20
Training> Name=main_level/agent, Worker=0, Episode=420, Total reward=0, Steps=14093, Training iteration=20
Policy training> Surrogate loss=0.0016354136168956757, KL divergence=0.025200873613357544, Entropy=2.8959248065948486, training epoch=0, learning_rate=0.0005
Policy training> Surrogate loss=-0.07514447718858719, KL divergence=0.04491401091217995, Entropy=2.9739203453063965, training epoch=1, learning_rate=0.0005
Policy training> Surrogate loss=-0.12103523313999176, KL divergence=0.0767117515206337, Entropy=2.8459296226501465, training epoch=2, learning_rate=0.0005
Policy training> Surrogate loss=-0.11855167150497437, KL divergence=0.07456786930561066, Entropy=2.8586292266845703, training epoch=3, learning_rate=0.0005
Policy training> Surrogate loss=-0.12274817377328873, KL divergence=0.07315459847450256, Entropy=2.8821399211883545, training epoch=4, learning_rate=0.0005
Policy training> Surrogate loss=-0.13274842500686646, KL divergence=0.07819752395153046, Entropy=2.8682384490966797, training epoch=5, learning_rate=0.0005
